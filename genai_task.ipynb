{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iiEIeGSxGiC",
        "outputId": "1b11135e-e889-49e2-eb12-a1fefae675b9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyZZ_adf3c7d",
        "outputId": "ae018743-f71d-4d4f-e2f3-66b1a27a93d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "\n",
        "# Load spaCy's pre-trained English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_text_from_pdf(pdf_file):\n",
        "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
        "    from PyPDF2 import PdfReader\n",
        "    pdf_reader = PdfReader(pdf_file)\n",
        "    text = ''\n",
        "    for page in pdf_reader.pages:\n",
        "        text += page.extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "057HzHJs31JU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_email(text):\n",
        "    \"\"\"Extracts email from text using regex and removes any invalid prefixes before the '@' symbol.\"\"\"\n",
        "    # Define a regex pattern to extract emails\n",
        "    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
        "\n",
        "    # Split the text into lines and join them to ensure email continuity across lines\n",
        "    lines = text.split('\\n')\n",
        "    joined_text = \" \".join(lines)\n",
        "\n",
        "    # Find all matches for email addresses\n",
        "    emails = re.findall(email_pattern, joined_text)\n",
        "\n",
        "    if emails:\n",
        "        # Iterate over the found emails and clean them if necessary\n",
        "        for email in emails:\n",
        "            # Check if there's any unwanted text before '@', ensuring valid email\n",
        "            email_parts = email.split('@')\n",
        "            if len(email_parts) == 2 and len(email_parts[0]) > 0:\n",
        "                # Return the cleaned email\n",
        "                return email\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "    # If no valid email is found, return a not-found message\n",
        "    return \"Email not found\"\n",
        "\n",
        "def extract_phone(text):\n",
        "    \"\"\"Extracts phone number from text using regex.\"\"\"\n",
        "    phone_pattern = r'\\+?\\d[\\d -]{8,12}\\d'\n",
        "    phone = re.findall(phone_pattern, text)\n",
        "    return phone[0] if phone else None\n",
        "\n",
        "def extract_name(text):\n",
        "    \"\"\"Extracts the name by looking for the first meaningful line and excluding non-name lines.\"\"\"\n",
        "    lines = text.split('\\n')\n",
        "    name = None\n",
        "\n",
        "    for line in lines[:15]:  # Focus on the first 15 lines of the document\n",
        "        line = line.strip()\n",
        "        if not line or \"@\" in line or any(char.isdigit() for char in line):  # Skip lines with emails, numbers\n",
        "            continue\n",
        "\n",
        "        # Assume the first meaningful line that doesn't contain numbers is the name\n",
        "        doc = nlp(line)\n",
        "        if len(doc.ents) > 0:\n",
        "            for ent in doc.ents:\n",
        "                if ent.label_ == \"PERSON\":\n",
        "                    name = ent.text\n",
        "                    break\n",
        "\n",
        "        if name:\n",
        "            break\n",
        "        else:\n",
        "            # If spaCy doesn't detect a name, use the line itself\n",
        "            return line if line else \"Name not found\"\n",
        "\n",
        "    return name if name else \"Name not found\"\n",
        "\n",
        "def extract_professional_summary(text):\n",
        "    \"\"\"Extracts the professional summary by capturing everything between 'Profile' and 'Professional Experience'.\"\"\"\n",
        "    lines = text.split('\\n')\n",
        "    summary = []\n",
        "    recording = False\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "\n",
        "        # Start recording after finding 'Profile'\n",
        "        if \"profile\" in line.lower() and not recording:\n",
        "            recording = True\n",
        "            continue\n",
        "\n",
        "        # Stop recording at 'Professional Experience' or similar section\n",
        "        if recording and (\"professional experience\" in line.lower() or \"experience\" in line.lower()):\n",
        "            break\n",
        "\n",
        "        # Record the lines that are part of the summary, excluding empty lines\n",
        "        if recording and line:\n",
        "            summary.append(line)\n",
        "\n",
        "    return ' '.join(summary).strip() if summary else \"Professional summary not found\"\n",
        "\n",
        "def extract_work_experience(text):\n",
        "    \"\"\"Extracts work experience by looking for keywords.\"\"\"\n",
        "    experience_keywords = [\"experience\", \"employment\", \"work history\", \"professional experience\"]\n",
        "    lines = text.split('\\n')\n",
        "    experience = []\n",
        "    recording = False\n",
        "\n",
        "    for line in lines:\n",
        "        if any(keyword.lower() in line.lower() for keyword in experience_keywords):\n",
        "            recording = True\n",
        "            continue\n",
        "        if recording and (line.strip() == '' or any(keyword.lower() in line.lower() for keyword in [\"education\", \"skills\"])):\n",
        "            break\n",
        "        if recording:\n",
        "            experience.append(line.strip())\n",
        "\n",
        "    return experience if experience else None\n",
        "\n",
        "def extract_education(text):\n",
        "    \"\"\"Extracts education details by looking for degree names.\"\"\"\n",
        "    degrees = [\"B.Sc\", \"M.Sc\", \"B.Tech\", \"M.Tech\", \"PhD\", \"Bachelor\", \"Master\", \"Doctorate\"]\n",
        "    education = []\n",
        "    for degree in degrees:\n",
        "        if degree.lower() in text.lower():\n",
        "            education.append(degree)\n",
        "    return education\n",
        "\n",
        "def extract_skills(text):\n",
        "    \"\"\"Extracts skills from text by looking for common skill keywords.\"\"\"\n",
        "    skills = [\"Python\", \"Java\", \"C++\", \"Machine Learning\", \"Data Science\", \"AI\", \"Deep Learning\", \"NLP\"]\n",
        "    extracted_skills = [skill for skill in skills if skill.lower() in text.lower()]\n",
        "    return extracted_skills\n",
        "\n",
        "def extract_certifications(text):\n",
        "    \"\"\"Extracts certifications by looking for common certification keywords and avoids educational references.\"\"\"\n",
        "    certification_keywords = [\"certification\", \"certified\", \"certificate\", \"accreditation\"]\n",
        "    lines = text.split('\\n')\n",
        "    certifications = []\n",
        "\n",
        "    recording = False\n",
        "    for line in lines:\n",
        "        if any(keyword.lower() in line.lower() for keyword in certification_keywords):\n",
        "            recording = True\n",
        "            certifications.append(line.strip())\n",
        "        elif recording and line.strip() == '':\n",
        "            break\n",
        "\n",
        "    # Filter out any mistakenly included education data\n",
        "    certifications = [cert for cert in certifications if not any(kw in cert.lower() for kw in [\"school\", \"examination\", \"secondary\"])]\n",
        "\n",
        "    return certifications if certifications else None"
      ],
      "metadata": {
        "id": "a59G_X8438tW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_resume(pdf_path):\n",
        "    \"\"\"Main function to process the resume from PDF.\"\"\"\n",
        "    resume_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "    resume_info = {\n",
        "        \"PersonalData\": {\n",
        "            \"Name\": extract_name(resume_text),\n",
        "            \"ContactInformation\": {\n",
        "                \"Email\": extract_email(resume_text),\n",
        "                \"Phone\": extract_phone(resume_text)\n",
        "            },\n",
        "            \"ProfessionalSummary\": extract_professional_summary(resume_text)\n",
        "        },\n",
        "        \"Experience\": extract_work_experience(resume_text),\n",
        "        \"Education\": extract_education(resume_text),\n",
        "        \"Skills\": extract_skills(resume_text),\n",
        "        \"Certifications\": extract_certifications(resume_text)\n",
        "    }\n",
        "\n",
        "    return resume_info\n"
      ],
      "metadata": {
        "id": "6ds3PliD4CEO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "pdf_file_path = '/content/drive/MyDrive/GenAI/SHRIYA CHOWDHURY RESUME.pdf'  # Path to your resume PDF\n",
        "resume_data = process_resume(pdf_file_path)\n",
        "\n",
        "# Output the extracted data\n",
        "print(resume_data)\n",
        "\n",
        "# Output the extracted data\n",
        "import json\n",
        "print(json.dumps(resume_data, indent=4))\n",
        "\n",
        "# You can save the extracted information into a JSON file\n",
        "with open('/content/extracted_resume.json', 'w') as json_file:\n",
        "    json.dump(resume_data, json_file, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMvOHqCM4FZU",
        "outputId": "21e98480-5b9c-43ba-9a3b-70e85730862e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'PersonalData': {'Name': 'Shriya Chowdhury', 'ContactInformation': {'Email': 'Singleshriyachowdhury24@gmail.com', 'Phone': '+919330563437'}, 'ProfessionalSummary': 'I am a pre-final year undergraduate student at VIT, Vellore pursuing B.Tech in Electronics and Communication Engineering. My primary areas of interest are Machine Learning, Data Science and Internet of Things. I have worked as a Product Design Intern and a Machine Learning Intern, which required me to polish my skills in Arduino Programming, building Deep Learning Models such as a Convolutional Neural Network Architecture for Binary Classification, Machine Learning Regression Models for Predicting House Prices, Image Processing and Optical Character Recognition for Text Feature Extraction, Relational Database Management using SQL and Natural Language Processing to build a Stacking Classifier for Fake News Prediction Modelling. Having been someone who loves continuous learning, I have always wanted to explore the horizons of technology.'}, 'Experience': ['2023/10 – 2023/12 Machine Learning Project Lead', 'YMoney, Microsecond Market', \"Project Lead in the compnay's Machine Learning and Computer Vision division involved\", 'working on an Automatic Robotic Classifier for use in Data Warehousing. The classifier used a', 'trained Object Detection model in YOLOV8 to identify barcodes, qrcodes and text information', 'on the label of the package and then further extract the textual information on the package', 'using Optical Character Recognition.', '2023/08 – 2023/09', 'Kolkata, IndiaProduct Design Intern', 'Centre for Development of Advanced Computing', 'Modelled a microcontroller based water dispensing system for automated tea tasting procedure', 'using Atmega328P microcontroller embedded in Arduino Uno R3 board.', '2023/07 – 2023/08 Machine Learning Intern', 'Fox Trading Solutions', 'Built a convolutional neural network model for binary classification using tensorflow and keras', 'libraries in python.'], 'Education': ['B.Tech'], 'Skills': ['Python', 'Java', 'Machine Learning', 'Data Science', 'AI', 'Deep Learning', 'NLP'], 'Certifications': ['Certificates', 'Microsoft Certified : Azure AI Fundamentals']}\n",
            "{\n",
            "    \"PersonalData\": {\n",
            "        \"Name\": \"Shriya Chowdhury\",\n",
            "        \"ContactInformation\": {\n",
            "            \"Email\": \"Singleshriyachowdhury24@gmail.com\",\n",
            "            \"Phone\": \"+919330563437\"\n",
            "        },\n",
            "        \"ProfessionalSummary\": \"I am a pre-final year undergraduate student at VIT, Vellore pursuing B.Tech in Electronics and Communication Engineering. My primary areas of interest are Machine Learning, Data Science and Internet of Things. I have worked as a Product Design Intern and a Machine Learning Intern, which required me to polish my skills in Arduino Programming, building Deep Learning Models such as a Convolutional Neural Network Architecture for Binary Classification, Machine Learning Regression Models for Predicting House Prices, Image Processing and Optical Character Recognition for Text Feature Extraction, Relational Database Management using SQL and Natural Language Processing to build a Stacking Classifier for Fake News Prediction Modelling. Having been someone who loves continuous learning, I have always wanted to explore the horizons of technology.\"\n",
            "    },\n",
            "    \"Experience\": [\n",
            "        \"2023/10 \\u2013 2023/12 Machine Learning Project Lead\",\n",
            "        \"YMoney, Microsecond Market\",\n",
            "        \"Project Lead in the compnay's Machine Learning and Computer Vision division involved\",\n",
            "        \"working on an Automatic Robotic Classifier for use in Data Warehousing. The classifier used a\",\n",
            "        \"trained Object Detection model in YOLOV8 to identify barcodes, qrcodes and text information\",\n",
            "        \"on the label of the package and then further extract the textual information on the package\",\n",
            "        \"using Optical Character Recognition.\",\n",
            "        \"2023/08 \\u2013 2023/09\",\n",
            "        \"Kolkata, IndiaProduct Design Intern\",\n",
            "        \"Centre for Development of Advanced Computing\",\n",
            "        \"Modelled a microcontroller based water dispensing system for automated tea tasting procedure\",\n",
            "        \"using Atmega328P microcontroller embedded in Arduino Uno R3 board.\",\n",
            "        \"2023/07 \\u2013 2023/08 Machine Learning Intern\",\n",
            "        \"Fox Trading Solutions\",\n",
            "        \"Built a convolutional neural network model for binary classification using tensorflow and keras\",\n",
            "        \"libraries in python.\"\n",
            "    ],\n",
            "    \"Education\": [\n",
            "        \"B.Tech\"\n",
            "    ],\n",
            "    \"Skills\": [\n",
            "        \"Python\",\n",
            "        \"Java\",\n",
            "        \"Machine Learning\",\n",
            "        \"Data Science\",\n",
            "        \"AI\",\n",
            "        \"Deep Learning\",\n",
            "        \"NLP\"\n",
            "    ],\n",
            "    \"Certifications\": [\n",
            "        \"Certificates\",\n",
            "        \"Microsoft Certified : Azure AI Fundamentals\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}